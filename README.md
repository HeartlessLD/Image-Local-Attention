# Image Local Attention: a Better PyTorch Implementation

## Introduction

Attention is widely used in deep learning cucently. Given a query `q`, a collection of keys `K` and value `V`. The output of an attention module is.

$$|\vec{A}|=\sqrt{A_x^2 + A_y^2 + A_z^2}.$$(1)
